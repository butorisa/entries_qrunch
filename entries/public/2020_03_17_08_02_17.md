---
title: 機械学習の数学入門 合成関数
tags:  機械学習 深層学習 数学
categories:  深層学習 数学
author: @buto
status: public
created_at: 2020-03-17 08:02:17 +0900
updated_at: 2020-03-17 12:10:53 +0900
published_at: 2020-03-17 09:27:57 +0900
---
勾配法+機械学習の勉強会の予習！
勉強会主催者より「合成関数の微分もできると良いです」なので、合成関数を学んでみた！
# 合成関数とは
*y = f(u), u = g(x) のとき* **y = f(g(x))** と表せる
```f(g(x))```と入れ子になっている関数のことを「f(u)とg(x)合成関数」という
# ニューラルネットワークと合成関数
ニューラルネットワークの各ノードで入力→出力された値は合成関数
→　ニューラルネットの学習結果（予測値）も合成関数
→　合成関数の微分ができると、学習結果に勾配降下法が適用できる！
# だからニューラルネットの出力値は合成関数
[ニューラルネットワーク 分かりやすくしてみた２](https://buto.qrunch.io/entries/jOnWorgr4OIkEPTr)でやってみたように
ニューラルネットワークはこんな計算がされている
1. 入力値に重みを掛けてバイアスを足す
1. ↑の計算結果に活性化関数を適用して出力

計算式にしてみると
（ｘ、ｙ：入力値　ｗ1、ｗ2：重み　ｂ：バイアス　ReLU：活性化関数）

1. 入力値に重みを掛けてバイアスを足す
    - xw1 + yw2 + b
1. 活性化関数を適用
    - ReLU(xw1 + yw2 + b)

`ReLU(xw1 + yw2 + b)`って合成関数だ！！
