---
title: ニューラルネットワーク わかりやすくしてみた
tags:  機械学習 深層学習
categories:  機械学習 深層学習
author: @buto
status: public
created_at: 2020-01-09 09:32:51 +0900
updated_at: 2020-01-12 18:35:01 +0900
published_at: 2020-01-09 12:32:06 +0900
---
# ニューラルネットワークの基礎をまとめる
[Chainerで始めるニューラルネットワーク](https://qiita.com/icoxfog417/items/96ecaff323434c8d677b)　←わかりやすい！
ニューラルネットワークで重回帰分析をする図を作りました
分析テーマは「都市の旅行客数を予測する」です
- 距離：東京からの距離
- 気温：平均気温
- 人口：その都市の人口

![undefined.jpg](https://s3.qrunch.io/ca563be44d0e77f98dd40c3df8e3f000.jpg)
### 入力層・隠れ層・出力層
**入力層**
分析に使うデータをインプットする
→　入力層のノード数は説明変数の個数と同じ

**隠れ層**
インプットされたデータを分析する
隠れ層は複数作成できる
中間層とも言う

**出力層**
分析された結果を出力する
犬か猫かだったら「0か1」、回帰分析など値を予測したら「500」（結果そのまま出力）
### 重み
入力値を隠れ層に渡すときには**重み**が掛けられる
（隠れ層1→隠れ層2…も重みが掛けられる）

重みは「この入力値の重視度」を値にしたもの
重みの値を大きくする　→　分析結果に与える影響を大きくする
（結果と高い相関がある変数だったら重みの値を大きくする）
### バイアス
[ニューラルネットワークと人間のバイアス（偏り）](https://bitwave.showcase-tv.com/%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF%E3%81%A8%E4%BA%BA%E9%96%93%E3%81%AE%E3%83%90%E3%82%A4%E3%82%A2%E3%82%B9/)
入力データの偏りを調整する値
偏りが結果に良い影響（予測精度が上がる）を与える　→　バイアスの値を大きくする
### 活性化関数
[活性化関数のまとめ（ステップ、シグモイド、ReLU、ソフトマックス、恒等関数）](https://qiita.com/namitop/items/d3d5091c7d0ab669195f)
各ノードで分析された結果を
「どういう値で出力（または次のノードへ渡す）するか」を決める関数

図では以下の時に活性化関数を使う
- 入力層　→　隠れ層
- 隠れ層　→　出力層

シグモイド関数、ReLUを使う…はイマイチ分かっていないので勉強中です！
